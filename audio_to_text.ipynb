{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "m95Y9j7ATnUE"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOXMpjKPJHBNIR1KSMnEQe7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fadel11-hub/Tim-Coba-Coba/blob/main/audio_to_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Audio To Text"
      ],
      "metadata": {
        "id": "kIMmX8qsTqFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Whisper (Open AI)"
      ],
      "metadata": {
        "id": "zUlxvm0_VMrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzYLp0aKhsm4",
        "outputId": "efeaab1d-def4-448f-c7a3-bdf3e62828d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O93N19E_TwTu",
        "outputId": "0e76a003-a62c-4ab2-c9b3-16b3c9240d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/803.2 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=a0e8927f669bd3ce7dcd9086347f0e8ce4b0c41bf88f9c2c38fa4acb9229cf40\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/d2/9a/801b5cc5b2a1af2e280089b71c326711a682fc1d50ea29d0ed\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20250625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Load the Whisper model\n",
        "# This might take some time on the first run as it downloads the model\n",
        "model_whisper = whisper.load_model(\"base\")\n",
        "\n",
        "# Transcribe the audio file\n",
        "# Make sure you have an audio file named \"audio.mp3\" in your environment\n",
        "result = model_whisper.transcribe(\"/content/drive/MyDrive/Datathon/Tim/Dokumen/Dataset/common_voice_id_25248253.mp3\")\n",
        "\n",
        "# Print the transcribed text\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8UkjAaMTsr-",
        "outputId": "95ec313c-7d23-45f6-ca64-bf4b91a91a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ada di lantai 3 bangunan ini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hugging Face (Jangan Pakai ini)"
      ],
      "metadata": {
        "id": "3Gg1txqSMhGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Daftar kata kunci darurat yang ingin kamu deteksi\n",
        "emergency_keywords = [\"tolong\", \"bantu saya\", \"saya diserang\", \"help\", \"emergency\", \"darurat\"]\n",
        "\n",
        "# Ubah hasil transkripsi ke huruf kecil untuk pencocokan\n",
        "transcribed_text = result[\"text\"].lower()\n",
        "\n",
        "# Cek apakah salah satu keyword ada di dalam teks\n",
        "if any(keyword in transcribed_text for keyword in emergency_keywords):\n",
        "    print(\"🚨 Deteksi situasi darurat! Kirim pesan SOS!\")\n",
        "    # Di sini kamu bisa tambah aksi, misal kirim WA/SMS/notifikasi\n",
        "else:\n",
        "    print(\"✅ Tidak ada kata darurat terdeteksi.\")\n"
      ],
      "metadata": {
        "id": "P7TlwAv1YpLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518eb93e-134e-49c1-cabd-92080d1f858d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tidak ada kata darurat terdeteksi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn joblib"
      ],
      "metadata": {
        "id": "P74ZoGtCckRH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "import os\n",
        "\n",
        "# Masukkan token Hugging Face\n",
        "os.environ[\"HF_TOKEN\"] = \"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\"\n",
        "\n",
        "# ✅ Pakai provider hf-inference\n",
        "client = InferenceClient(\n",
        "    api_key=os.environ[\"HF_TOKEN\"],\n",
        "    provider=\"hf-inference\"\n",
        ")\n",
        "\n",
        "# ✅ Jalankan Whisper\n",
        "output = client.automatic_speech_recognition(\n",
        "    \"/content/drive/MyDrive/Datathon/Tim/Dokumen/Dataset/common_voice_id_25248253.mp3\",\n",
        "    model=\"openai/whisper-large-v3\"\n",
        ")\n",
        "\n",
        "# ✅ Tampilkan hasil\n",
        "print(\"📝 Hasil Transkripsi:\")\n",
        "print(output[\"text\"])\n"
      ],
      "metadata": {
        "id": "1Hsjdkahqhj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Jalankan Whisper di subprocess\n",
        "subprocess.run([\n",
        "    \"python3\", \"-c\",\n",
        "    \"\"\"\n",
        "import whisper\n",
        "model = whisper.load_model('base')\n",
        "result = model.transcribe('/content/drive/MyDrive/Datathon/Tim/Dokumen/Dataset/common_voice_id_25248253.mp3')\n",
        "print(result['text'])\n",
        "    \"\"\"\n",
        "])\n"
      ],
      "metadata": {
        "id": "f2If56_DtrOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bangun Model Klasifikasi"
      ],
      "metadata": {
        "id": "dfELPlxpVIAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "Odi-cikxhGcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Load CSV dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Datathon/Tim/Dokumen/Dataset/darurat_aman_dataset.csv\")  # Pastikan file ini ada\n",
        "\n",
        "print(df)\n",
        "\n",
        "# sentences = []\n",
        "# labels = []\n",
        "\n",
        "# for item in df:\n",
        "#   sentences.append(item['text'])\n",
        "#   labels.append(item['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnducSShhkcw",
        "outputId": "e2f09abe-e78b-42c3-a027-d7acec69e130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           text    label\n",
            "0          Tolong saya, ada yang mengejar saya.  darurat\n",
            "1                Bantu saya! Saya dalam bahaya.  darurat\n",
            "2    Orang ini mencurigakan dan mengikuti saya.  darurat\n",
            "3              Ada kebakaran di rumah tetangga.  darurat\n",
            "4                      Saya baru saja dirampok.  darurat\n",
            "..                                          ...      ...\n",
            "199            Saya mencoba resep makanan baru.     aman\n",
            "200                 Saya mengecek email kantor.     aman\n",
            "201             Saya bermain ukulele di balkon.     aman\n",
            "202             Saya menonton video dokumenter.     aman\n",
            "203             Saya menyetrika baju tadi pagi.     aman\n",
            "\n",
            "[204 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['text'].astype(str).tolist()\n",
        "# Map 'aman' to 0 and 'darurat' to 1\n",
        "label_mapping = {'aman': 0, 'darurat': 1}\n",
        "labels = df['label'].map(label_mapping).astype(int).tolist()"
      ],
      "metadata": {
        "id": "Sy2F1qJnTd10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "training_padded = pad_sequences(sequences, padding='post', truncating='post')\n",
        "\n",
        "print('\\n Word index =', word_index)\n",
        "print('\\n Sequences =', sequences)\n",
        "print('\\n Padded Sequences:')\n",
        "print(training_padded)\n",
        "\n",
        "# Convert the labels lists into numpy arrays\n",
        "training_labels = np.array(labels)\n",
        "print(training_labels)"
      ],
      "metadata": {
        "id": "TLsE629qPyP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88acaf08-577c-47f7-c114-9880647de0c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Word index = {'<OOV>': 1, 'saya': 2, 'di': 3, 'ada': 4, 'orang': 5, 'ini': 6, 'rumah': 7, 'sedang': 8, 'tolong': 9, 'ke': 10, 'hari': 11, 'dalam': 12, 'tidak': 13, 'mencoba': 14, 'jalan': 15, 'yang': 16, 'dan': 17, 'baru': 18, 'sekarang': 19, 'melihat': 20, 'tadi': 21, 'menonton': 22, 'bermain': 23, 'teman': 24, 'pagi': 25, 'membuat': 26, 'itu': 27, 'keluar': 28, 'seseorang': 29, 'butuh': 30, 'kamar': 31, 'beres': 32, 'dari': 33, 'bersama': 34, 'belajar': 35, 'dengan': 36, 'video': 37, 'bantu': 38, 'mencurigakan': 39, 'mengikuti': 40, 'lokasi': 41, 'bisa': 42, 'masuk': 43, 'suara': 44, 'membobol': 45, 'pintu': 46, 'besar': 47, 'bantuan': 48, 'dikenal': 49, 'terkunci': 50, 'merasa': 51, 'pertolongan': 52, 'segera': 53, 'ruangan': 54, 'mendengar': 55, 'diserang': 56, 'pingsan': 57, 'anak': 58, 'pulang': 59, 'motor': 60, 'kucing': 61, 'terjebak': 62, 'umum': 63, 'taman': 64, 'menikmati': 65, 'waktu': 66, 'santai': 67, 'favorit': 68, 'kantor': 69, 'membaca': 70, 'sore': 71, 'menulis': 72, 'mingguan': 73, 'siang': 74, 'lama': 75, 'baju': 76, 'mengejar': 77, 'bahaya': 78, 'kebakaran': 79, 'tetangga': 80, 'saja': 81, 'dirampok': 82, 'cepat': 83, 'kirim': 84, 'ambulans': 85, 'membawa': 86, 'senjata': 87, 'tajam': 88, 'memaksa': 89, 'hubungi': 90, 'polisi': 91, 'juga': 92, 'dengar': 93, 'tembakan': 94, 'luar': 95, 'pencuri': 96, 'kecelakaan': 97, 'medis': 98, 'mengintai': 99, 'mobil': 100, 'mogok': 101, 'tol': 102, 'tengah': 103, 'malam': 104, 'perkelahian': 105, 'depan': 106, 'lingkungan': 107, 'terancam': 108, 'membutuhkan': 109, 'sendirian': 110, 'merampas': 111, 'tas': 112, 'diculik': 113, 'lacak': 114, 'menyekap': 115, 'atap': 116, 'lewat': 117, 'jendela': 118, 'berada': 119, 'situasi': 120, 'genting': 121, 'datang': 122, 'alamat': 123, 'hilang': 124, 'pusat': 125, 'perbelanjaan': 126, 'saat': 127, 'berjalan': 128, 'tak': 129, 'menggedor': 130, 'diikuti': 131, 'sejak': 132, 'teriakan': 133, 'minta': 134, 'sumur': 135, 'asap': 136, 'lantai': 137, 'atas': 138, 'kemasukan': 139, 'ular': 140, 'mandi': 141, 'merampok': 142, 'toko': 143, 'tahu': 144, 'harus': 145, 'mana': 146, 'mabuk': 147, 'mengganggu': 148, 'takut': 149, 'kesulitan': 150, 'kecil': 151, 'tersesat': 152, 'menangis': 153, 'lift': 154, 'darurat': 155, 'sarapan': 156, 'keluarga': 157, 'cuaca': 158, 'sangat': 159, 'cerah': 160, 'film': 161, 'untuk': 162, 'ujian': 163, 'memasak': 164, 'nasi': 165, 'goreng': 166, 'buku': 167, 'gitar': 168, 'mall': 169, 'jogging': 170, 'membersihkan': 171, 'catatan': 172, 'harian': 173, 'berbelanja': 174, 'kebutuhan': 175, 'menelepon': 176, 'ibu': 177, 'duduk': 178, 'sambil': 179, 'minum': 180, 'teh': 181, 'makan': 182, 'restoran': 183, 'dekat': 184, 'mencuci': 185, 'acara': 186, 'tv': 187, 'berkunjung': 188, 'berolahraga': 189, 'ringan': 190, 'kue': 191, 'coklat': 192, 'mendengarkan': 193, 'musik': 194, 'jazz': 195, 'animasi': 196, '3d': 197, 'menggambar': 198, 'pemandangan': 199, 'game': 200, 'online': 201, 'lemari': 202, 'edukatif': 203, 'youtube': 204, 'menyiram': 205, 'tanaman': 206, 'hias': 207, 'kelas': 208, 'bahasa': 209, 'inggris': 210, 'daring': 211, 'membantu': 212, 'adik': 213, 'mengerjakan': 214, 'pr': 215, 'mengedit': 216, 'perjalanan': 217, 'browsing': 218, 'artikel': 219, 'teknologi': 220, 'berbaring': 221, 'kasur': 222, 'puisi': 223, 'kafe': 224, 'desain': 225, 'poster': 226, 'digital': 227, 'mengatur': 228, 'jadwal': 229, 'memandikan': 230, 'anjing': 231, 'peliharaan': 232, 'menyortir': 233, 'foto': 234, 'laptop': 235, 'kopi': 236, 'alat': 237, 'manual': 238, 'brew': 239, 'koran': 240, 'coding': 241, 'python': 242, 'mencatat': 243, 'pengeluaran': 244, 'bulanan': 245, 'merekam': 246, 'podcast': 247, 'mengunjungi': 248, 'perpustakaan': 249, 'resep': 250, 'makanan': 251, 'mengecek': 252, 'email': 253, 'ukulele': 254, 'balkon': 255, 'dokumenter': 256, 'menyetrika': 257}\n",
            "\n",
            " Sequences = [[9, 2, 4, 16, 77, 2], [38, 2, 2, 12, 78], [5, 6, 39, 17, 40, 2], [4, 79, 3, 7, 80], [2, 18, 81, 82], [83, 84, 85, 10, 41, 2], [5, 27, 86, 87, 88], [2, 13, 42, 28, 9, 38], [4, 16, 89, 43, 10, 7, 2], [9, 90, 91, 19, 92], [2, 93, 44, 94, 3, 95], [4, 96, 3, 7, 2], [29, 14, 45, 46, 2], [2, 20, 97, 47, 3, 15], [2, 30, 48, 98, 19], [4, 5, 13, 49, 99, 2], [100, 2, 101, 3, 15, 102, 103, 104], [2, 50, 3, 12, 31], [2, 20, 105, 47, 3, 106, 7], [9, 4, 16, 13, 32, 3, 107, 2], [2, 51, 108, 19], [2, 109, 52, 53], [2, 110, 17, 13, 42, 28], [29, 14, 111, 112, 2], [2, 113, 9, 114, 41, 2], [4, 16, 115, 2, 3, 54, 6], [2, 55, 44, 39, 3, 116], [2, 8, 56, 19], [5, 27, 14, 43, 117, 118], [2, 119, 12, 120, 121], [9, 53, 122, 10, 123, 2], [2, 20, 5, 57, 3, 15], [58, 2, 124, 3, 125, 126], [2, 56, 127, 128, 59], [5, 129, 49, 130, 46, 2], [2, 51, 131, 132, 21], [29, 8, 45, 60, 2], [2, 55, 133, 134, 9], [61, 2, 62, 3, 12, 135], [2, 20, 136, 33, 137, 138], [7, 2, 139, 140], [2, 50, 3, 31, 141, 63], [5, 27, 14, 142, 143], [2, 13, 144, 145, 10, 146], [4, 5, 147, 148, 2], [2, 149, 28, 33, 54, 6], [2, 8, 150, 17, 30, 48], [4, 5, 57, 3, 64], [58, 151, 152, 17, 153], [2, 62, 3, 12, 154], [2, 30, 52, 155], [9, 2, 4, 16, 77, 2], [38, 2, 2, 12, 78], [5, 6, 39, 17, 40, 2], [4, 79, 3, 7, 80], [2, 18, 81, 82], [83, 84, 85, 10, 41, 2], [5, 27, 86, 87, 88], [2, 13, 42, 28, 9, 38], [4, 16, 89, 43, 10, 7, 2], [9, 90, 91, 19, 92], [2, 93, 44, 94, 3, 95], [4, 96, 3, 7, 2], [29, 14, 45, 46, 2], [2, 20, 97, 47, 3, 15], [2, 30, 48, 98, 19], [4, 5, 13, 49, 99, 2], [100, 2, 101, 3, 15, 102, 103, 104], [2, 50, 3, 12, 31], [2, 20, 105, 47, 3, 106, 7], [9, 4, 16, 13, 32, 3, 107, 2], [2, 51, 108, 19], [2, 109, 52, 53], [2, 110, 17, 13, 42, 28], [29, 14, 111, 112, 2], [2, 113, 9, 114, 41, 2], [4, 16, 115, 2, 3, 54, 6], [2, 55, 44, 39, 3, 116], [2, 8, 56, 19], [5, 27, 14, 43, 117, 118], [2, 119, 12, 120, 121], [9, 53, 122, 10, 123, 2], [2, 20, 5, 57, 3, 15], [58, 2, 124, 3, 125, 126], [2, 56, 127, 128, 59], [5, 129, 49, 130, 46, 2], [2, 51, 131, 132, 21], [29, 8, 45, 60, 2], [2, 55, 133, 134, 9], [61, 2, 62, 3, 12, 135], [2, 20, 136, 33, 137, 138], [7, 2, 139, 140], [2, 50, 3, 31, 141, 63], [5, 27, 14, 142, 143], [2, 13, 144, 145, 10, 146], [4, 5, 147, 148, 2], [2, 149, 28, 33, 54, 6], [2, 8, 150, 17, 30, 48], [4, 5, 57, 3, 64], [58, 151, 152, 17, 153], [2, 62, 3, 12, 154], [2, 30, 52, 155], [2, 8, 156, 34, 157], [158, 11, 6, 159, 160], [2, 65, 66, 67, 3, 64], [21, 2, 22, 161, 68, 2], [2, 8, 35, 162, 163], [11, 6, 2, 164, 165, 166], [2, 18, 59, 33, 69], [2, 70, 167, 3, 31], [2, 23, 168, 3, 71, 11], [2, 15, 15, 10, 169, 34, 24], [11, 6, 2, 170, 3, 25, 11], [2, 171, 7, 11, 6], [2, 8, 72, 172, 173], [2, 23, 36, 61, 2], [2, 174, 175, 73], [2, 8, 176, 177, 2], [2, 178, 67, 179, 180, 181], [2, 182, 74, 3, 183, 184, 7], [2, 185, 60, 25, 6], [2, 8, 22, 186, 187, 68], [2, 188, 10, 7, 24, 75], [2, 189, 190, 3, 7], [2, 26, 191, 192, 21, 74], [2, 193, 194, 195], [2, 35, 26, 196, 197], [2, 198, 199, 71], [2, 23, 200, 201, 34, 24], [2, 32, 32, 202, 76], [2, 22, 37, 203, 3, 204], [2, 8, 205, 206, 207], [2, 40, 208, 209, 210, 211], [2, 212, 213, 214, 215], [2, 216, 37, 217, 2], [2, 218, 219, 220, 18], [2, 221, 3, 222, 65, 66], [2, 72, 223, 3, 224], [2, 26, 225, 226, 227], [2, 228, 229, 73, 2], [2, 230, 231, 232, 2], [2, 233, 234, 75, 3, 235], [2, 26, 236, 36, 237, 238, 239], [2, 70, 240, 25, 6], [2, 35, 241, 242], [2, 243, 244, 245], [2, 246, 247, 36, 24], [2, 248, 249, 63], [2, 14, 250, 251, 18], [2, 252, 253, 69], [2, 23, 254, 3, 255], [2, 22, 37, 256], [2, 257, 76, 21, 25], [2, 8, 156, 34, 157], [158, 11, 6, 159, 160], [2, 65, 66, 67, 3, 64], [21, 2, 22, 161, 68, 2], [2, 8, 35, 162, 163], [11, 6, 2, 164, 165, 166], [2, 18, 59, 33, 69], [2, 70, 167, 3, 31], [2, 23, 168, 3, 71, 11], [2, 15, 15, 10, 169, 34, 24], [11, 6, 2, 170, 3, 25, 11], [2, 171, 7, 11, 6], [2, 8, 72, 172, 173], [2, 23, 36, 61, 2], [2, 174, 175, 73], [2, 8, 176, 177, 2], [2, 178, 67, 179, 180, 181], [2, 182, 74, 3, 183, 184, 7], [2, 185, 60, 25, 6], [2, 8, 22, 186, 187, 68], [2, 188, 10, 7, 24, 75], [2, 189, 190, 3, 7], [2, 26, 191, 192, 21, 74], [2, 193, 194, 195], [2, 35, 26, 196, 197], [2, 198, 199, 71], [2, 23, 200, 201, 34, 24], [2, 32, 32, 202, 76], [2, 22, 37, 203, 3, 204], [2, 8, 205, 206, 207], [2, 40, 208, 209, 210, 211], [2, 212, 213, 214, 215], [2, 216, 37, 217, 2], [2, 218, 219, 220, 18], [2, 221, 3, 222, 65, 66], [2, 72, 223, 3, 224], [2, 26, 225, 226, 227], [2, 228, 229, 73, 2], [2, 230, 231, 232, 2], [2, 233, 234, 75, 3, 235], [2, 26, 236, 36, 237, 238, 239], [2, 70, 240, 25, 6], [2, 35, 241, 242], [2, 243, 244, 245], [2, 246, 247, 36, 24], [2, 248, 249, 63], [2, 14, 250, 251, 18], [2, 252, 253, 69], [2, 23, 254, 3, 255], [2, 22, 37, 256], [2, 257, 76, 21, 25]]\n",
            "\n",
            " Padded Sequences:\n",
            "[[  9   2   4 ...   2   0   0]\n",
            " [ 38   2   2 ...   0   0   0]\n",
            " [  5   6  39 ...   2   0   0]\n",
            " ...\n",
            " [  2  23 254 ...   0   0   0]\n",
            " [  2  22  37 ...   0   0   0]\n",
            " [  2 257  76 ...   0   0   0]]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Global Average"
      ],
      "metadata": {
        "id": "Eh1CFwqNYk6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of examples to use for training\n",
        "training_size = 20000\n",
        "\n",
        "# Vocabulary size of the tokenizer\n",
        "vocab_size = 10000\n",
        "\n",
        "# Maximum length of the padded sequences\n",
        "max_length = 32\n",
        "\n",
        "# Output dimensions of the Embedding layer\n",
        "embedding_dim = 16"
      ],
      "metadata": {
        "id": "pIkVTWYoX5tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Global Average"
      ],
      "metadata": {
        "id": "LG0D8FrWMOEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jangan pakai yang ini"
      ],
      "metadata": {
        "id": "BIQrumjbMYSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Setup the training parameters\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "szqNMq45XYVB",
        "outputId": "5d714d17-4f0a-498e-c7d7-0c1d54b9eb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pakai Ini"
      ],
      "metadata": {
        "id": "dPdAnShDMcel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    GlobalAveragePooling1D(),  # rata-rata embedding\n",
        "    Dense(6, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLRKYsYeE_77",
        "outputId": "7cc5e559-0cb3-423a-c2ca-7c560bc3f45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BTFy8PeHX-Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(training_padded, training_labels, epochs=num_epochs, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsrGu5w7YKqz",
        "outputId": "54710f53-20eb-4c05-c0f7-494ce6c2b4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "7/7 - 2s - 255ms/step - accuracy: 0.5882 - loss: 0.6928\n",
            "Epoch 2/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.8039 - loss: 0.6893\n",
            "Epoch 3/30\n",
            "7/7 - 0s - 11ms/step - accuracy: 0.9461 - loss: 0.6856\n",
            "Epoch 4/30\n",
            "7/7 - 0s - 18ms/step - accuracy: 0.9902 - loss: 0.6815\n",
            "Epoch 5/30\n",
            "7/7 - 0s - 20ms/step - accuracy: 0.9902 - loss: 0.6768\n",
            "Epoch 6/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.6715\n",
            "Epoch 7/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.6653\n",
            "Epoch 8/30\n",
            "7/7 - 0s - 20ms/step - accuracy: 0.9902 - loss: 0.6580\n",
            "Epoch 9/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.6496\n",
            "Epoch 10/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.6400\n",
            "Epoch 11/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.6294\n",
            "Epoch 12/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.6178\n",
            "Epoch 13/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.6054\n",
            "Epoch 14/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.5921\n",
            "Epoch 15/30\n",
            "7/7 - 0s - 10ms/step - accuracy: 0.9902 - loss: 0.5779\n",
            "Epoch 16/30\n",
            "7/7 - 0s - 18ms/step - accuracy: 0.9902 - loss: 0.5626\n",
            "Epoch 17/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.5464\n",
            "Epoch 18/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.5297\n",
            "Epoch 19/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.5120\n",
            "Epoch 20/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.4940\n",
            "Epoch 21/30\n",
            "7/7 - 0s - 20ms/step - accuracy: 0.9902 - loss: 0.4751\n",
            "Epoch 22/30\n",
            "7/7 - 0s - 10ms/step - accuracy: 0.9902 - loss: 0.4557\n",
            "Epoch 23/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.4364\n",
            "Epoch 24/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.4166\n",
            "Epoch 25/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.3971\n",
            "Epoch 26/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.3775\n",
            "Epoch 27/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.3580\n",
            "Epoch 28/30\n",
            "7/7 - 0s - 20ms/step - accuracy: 1.0000 - loss: 0.3390\n",
            "Epoch 29/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.3205\n",
            "Epoch 30/30\n",
            "7/7 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.3025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Model"
      ],
      "metadata": {
        "id": "a0xp__u5kNuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. LSTM Model ---\n",
        "model_lstm = Sequential([\n",
        "    Embedding(input_dim=1000, output_dim=16),\n",
        "    LSTM(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm.fit(training_padded, training_labels, epochs=10, verbose=2)"
      ],
      "metadata": {
        "id": "m5C1JooyP1r1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe the audio file\n",
        "# Make sure you have an audio file named \"audio.mp3\" in your environment\n",
        "result2 = model_whisper.transcribe(\"/content/drive/MyDrive/Datathon/Tim/Dokumen/Dataset/Dataset darurat.m4a\")\n",
        "\n",
        "# Print the transcribed text\n",
        "print(result2[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-L97pDIGi3h",
        "outputId": "0e8d0676-ab92-4bb7-ce7b-e05979248875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tala Bantu gue Tala\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Prediksi Teks dari Whisper ---\n",
        "input_seq = tokenizer.texts_to_sequences(result2['text'])\n",
        "input_pad = pad_sequences(input_seq, maxlen=10, padding='post')\n",
        "\n",
        "pred = model.predict(input_pad)[0][0]\n",
        "print(\"Status:\", \"🚨 darurat\" if pred > 0.5 else \"✅ aman\")"
      ],
      "metadata": {
        "id": "TCFVw7w8P6zk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d296c28-059e-451b-9b3e-e94ddd989318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
            "Status: ✅ aman\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "zRN-V4eWYoxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kebutuhan optional"
      ],
      "metadata": {
        "id": "Ff0Nyc9VMIx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SSly5bkyrRo",
        "outputId": "5e613e7b-3c4b-427f-9ad2-978d19691d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.19.0\n",
            "Uninstalling tensorflow-2.19.0:\n",
            "  Successfully uninstalled tensorflow-2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Cek versi TensorFlow\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Cek apakah GPU tersedia\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"✅ GPU is available!\")\n",
        "else:\n",
        "    print(\"❌ GPU not available.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oubvk4Gee9x0",
        "outputId": "c30f8a89-f06b-4080-d26f-543a757abb5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "✅ GPU is available!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('tf', tf.__version__)\n",
        "!pip show tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkxXtrljudBW",
        "outputId": "435c3410-b545-47b1-f2a8-6265dfe820ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf 2.19.0\n",
            "Name: tensorflow\n",
            "Version: 2.19.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine_rl, tensorflow-text, tensorflow_decision_forests, tf_keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iL8rM4awj6u",
        "outputId": "4b82456f-450b-4c92-dcc9-9d63d5578b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ],
      "metadata": {
        "id": "QzUPEGTpiS6U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}